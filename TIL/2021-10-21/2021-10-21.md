# working

## spark

### installation in windows10

**requirements**
JAVA 11 (with 환경변수)
Python > 3.0(3.6으로 설치함)

1. spark 다운로드  
(spark-3.1.2-hadoop-3.2로 설치함)  
하둡이 있다면 릴리즈에 맞춰 다운로드.  
링크 : https://spark.apache.org/downloads.html  
원하는 폴더로 이동(e.g. C:/Users/user/spark)  
압축해제 및 편의상 폴더 이름 변경(spark-3.1.2)

2. winutils 다운로드  
(아마 hadoop의 mock 파일인것으로 추정)  
다운로드받은 spark 버전 뒤쪽 hadoop와 같은 release.   
winutils.exe 다운로드  
링크 : https://github.com/cdarlint/winutils  
원하는 폴더 + bin 으로 이동(e.g. C:/Users/user/hadoop/bin)

3. 환경변수 설정
환경 변수 -> 시스템 변수 -> 새로만들기
1) SPARK_HOME & C:/Users/user/spark/spark-3.1.2
2) HADOOP_HOME & C:/Users/user/hadoop

PATH 수정  
시스템 변수 중 Path를 선택해서 편집 & 새로 만들기  
1) %SPARK_HOME%\bin
2) %HADOOP_HOME%\bin

4. 동작 확인
```python
lines = sc.textFile("some_file")
lines.count()
lines.first()
```

#### trouble shoot
현상 : sc.textFile("some_file") 에서 에러 발생  

원인 : python3 명령어를 찾지 못함. pyspark 내부에서 python이 아닌 python3 명령어를 사용하기 때문에 발생하는 문제인것으로 추정  

해결 방안 : 설치한 python 폴더(C:\Users\user\AppData\Local\Programs\Python\Python36) 의 python.exe를 복사하여 python3.exe 를 만듬.  

