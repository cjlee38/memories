# working
## hadoop
### Chapter 3. HDFS의 이해(이어서)


#### 1분에 24GB가 생기는 데이터가 있다고 해보자.
즉, time-series data가 있다고 할 때. 하둡은 데이터를 어떻게 저장하는가? (스타트는 어떻게든 끊을 수 있다. e.g. 하둡 런 or 카프카)  
1. 24GB를 128MB(블록) 단위로 쪼갠다.
2. 쪼갠 데이터의 적절한 위치(같은 내용인 복제 블록은 같은 노드에 저장되지 않음)에 저장한다.
3. slave가 master에게 3초마다 heart-beat(헬스체크)를 보낸다.
4. 만약 heart-beat가 일정 시간 오지 않으면, 해당 데이터노드를 장애로 생각
5. 네임노드는 어떤 데이터의 어떤 블록이 어디 노드에 저장되어있는지 알고 있다.
6. 따라서, 장애가 발생하면 다른 Node에서 데이터를 가져와서 또 다른 Node에 복제해놓는다.

> 만약 노드의 실제 장애가 아니고, 단순 네트워크 오류라면?
> replication이 4개여도, 3개로 다시 줄여줌.

#### hadoop이 데이터 유실될 수 있는 Case
-> 3개의 데이터노드가 모두 장애가 날때.  
hadoop 자체의 문제로 인해 데이터를 유실되는 경우는 거의 없다.

#### Master Node가 고장났을때 ?
-> Secondary Node를 두고, Master Node의 Replication.

#### Locality
MapReduce와 같은 연산을 진행할 때, 데이터를 마스터 노드로 갖고와서 계산하는 것이 아니라, 데이터 노드 자체에서 계산하도록 하는 것  
\+ 같은 Rack 안에서도 빠르게 동작하도록 할 수 있다.

#### Block Cache
자주 읽는 블록은 '블록 캐시'라는 데이터 노드의 메모리에 명시적으로 캐싱해놓을 수 있다.

#### Secondary Name Node
네임 노드는 전체 파일 시스템의 정보를 다 알고 있다.  
edits와 fsimage가 있는데,   
edits는 메모리에 쌓다가 어느정도 쌓이면 flush to file.   
fsimage는 이 edits라는 log를 보고 인지하고 있는 metadata

fsimage에 병합할때, secondary로 보내고, secondary가 merge를 해주고, 이를 다시 namenode로 보낸다.

#### data node
datanode는 물리적으로 file system에 저장. 
